{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Traditional_Dropout.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyNwLPpp56tU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "5a708bcb-3dcd-423e-e6f1-77a2b1a446e1"
      },
      "source": [
        "# All imports\n",
        "\n",
        "from google.colab import files\n",
        "from IPython.display import Image,display\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import timeit\n",
        "import os\n",
        "import psutil"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NCr-9tZs65w",
        "colab_type": "code",
        "outputId": "d1435932-3272-494f-d05b-c7d5f090fb1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# GPU Support\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qNWYuDIJTrW",
        "colab_type": "text"
      },
      "source": [
        "#Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0FXSFhZQgSy",
        "colab_type": "code",
        "outputId": "c32b58f1-62cd-4196-b9ff-65bb739fd4b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "# loading the MNIST dataset, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# To print the image of the written number along with the value in the y column\n",
        "image_index = 1                 # You may select anything up to y_train.shape[0]\n",
        "\n",
        "plt.imshow(x_train[image_index], cmap='Greys')\n",
        "print(\"The handwritten number is \", y_train[image_index])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The handwritten number is  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qv8qA3VqJcHB",
        "colab_type": "text"
      },
      "source": [
        "#Preprocessing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-DzsWa9Tbyc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating training set\n",
        "training_size = 25600\n",
        "\n",
        "# Creating test set\n",
        "test_size = 256\n",
        "\n",
        "# Number of epochs\n",
        "epoch= 180"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fj5k9x0QtWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "\n",
        "# Ensuring the datatype is float\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# Normalizing RGB codes by dividing by the max RGB value.\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "\n",
        "y_train.reshape(y_train.shape[0],1)\n",
        "y_test.reshape(y_test.shape[0],1)\n",
        "\n",
        "# Converting to categorical values, one hot encoding\n",
        "num_classes = 10\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        " \n",
        "x_train1 = x_train[0:training_size,:,:,:]\n",
        "y_train1 = y_train[0:training_size,:]\n",
        "\n",
        "x_test1 = x_test[0:test_size,:,:,:]\n",
        "y_test1 = y_test[0:test_size,:]\n",
        "\n",
        "x_train1 = x_train1.reshape(x_train1.shape[0], 784, )\n",
        "x_test1 = x_test1.reshape(x_test1.shape[0], 784, )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPYKUporJiCc",
        "colab_type": "text"
      },
      "source": [
        "#Creating the Neural Network Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plK11RKH6WEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CREATING NN ARCHITECTURE 784-2000-2000-10\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dropout(0, input_shape=(784,)))         # Input Layer\n",
        "model.add(tf.keras.layers.Dense(units=2000, activation='relu'))   # ReLU activation on hidden layer 1\n",
        "model.add(tf.keras.layers.Dropout(0.5))                           # Dropout on hidden layer 1\n",
        "model.add(tf.keras.layers.Dense(units=2000, activation='relu'))   # Relu activation on hidden layer 2\n",
        "model.add(tf.keras.layers.Dropout(0.5))                           # Dropout on hidden layer 2\n",
        "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))  # Softmax on the output layer\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WD7QACR8JniU",
        "colab_type": "text"
      },
      "source": [
        "#Creating a Neural Network and training it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWolxOzA7ueM",
        "colab_type": "code",
        "outputId": "519bbece-c3a6-4ec9-8618-7f862a960a6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "start = timeit.default_timer()\n",
        "\n",
        "y_acc= []\n",
        "x_plt = []\n",
        "\n",
        "# Compiling the model with CrossEntropy Loss and using the Adam optimizer for the classification problem\n",
        "model.compile(loss=tf.keras.losses.categorical_crossentropy,optimizer =  tf.keras.optimizers.Adam( learning_rate=0.00005,\n",
        "              beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name='Adam') ,metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Training the model for epoch number of iterations\n",
        "for i in range(int(epoch/3)):         \n",
        "  dropout_history = model.fit(x_train1, y_train1, epochs=3, batch_size= 256,validation_split=0.1,verbose = 1,shuffle=True)\n",
        "  \n",
        "  # if(i%3 == 0):               # Evaluating the model every 200-300 weight updates\n",
        "  y_acc.append(1 - model.evaluate(x_test1, y_test1, batch_size=256)[1])\n",
        "  x_plt.append(3*i*training_size/256)\n",
        "\n",
        "finish = timeit.default_timer()\n",
        "\n",
        "# Evaluating the model on test set after training is complete\n",
        "y_plt =dropout_history.history['val_loss']\n",
        "results = model.evaluate(x_test1, y_test1, batch_size= 256)\n",
        "print('Test accuracy : ', results[0],results[1])\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 1.2846 - accuracy: 0.6613 - val_loss: 0.5250 - val_accuracy: 0.8613\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.4964 - accuracy: 0.8607 - val_loss: 0.3463 - val_accuracy: 0.9000\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.3781 - accuracy: 0.8923 - val_loss: 0.2862 - val_accuracy: 0.9133\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2372 - accuracy: 0.9375\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.3230 - accuracy: 0.9071 - val_loss: 0.2615 - val_accuracy: 0.9207\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.2854 - accuracy: 0.9178 - val_loss: 0.2293 - val_accuracy: 0.9305\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.2555 - accuracy: 0.9266 - val_loss: 0.2146 - val_accuracy: 0.9355\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1586 - accuracy: 0.9570\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.2317 - accuracy: 0.9346 - val_loss: 0.1983 - val_accuracy: 0.9402\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.2112 - accuracy: 0.9393 - val_loss: 0.1809 - val_accuracy: 0.9441\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.1972 - accuracy: 0.9423 - val_loss: 0.1745 - val_accuracy: 0.9465\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1202 - accuracy: 0.9688\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.1814 - accuracy: 0.9492 - val_loss: 0.1614 - val_accuracy: 0.9480\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.1691 - accuracy: 0.9521 - val_loss: 0.1531 - val_accuracy: 0.9488\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.1572 - accuracy: 0.9536 - val_loss: 0.1459 - val_accuracy: 0.9520\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1003 - accuracy: 0.9766\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.1462 - accuracy: 0.9578 - val_loss: 0.1394 - val_accuracy: 0.9551\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.1391 - accuracy: 0.9605 - val_loss: 0.1344 - val_accuracy: 0.9551\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.1292 - accuracy: 0.9626 - val_loss: 0.1290 - val_accuracy: 0.9582\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0859 - accuracy: 0.9883\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.1219 - accuracy: 0.9648 - val_loss: 0.1262 - val_accuracy: 0.9582\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.1160 - accuracy: 0.9666 - val_loss: 0.1219 - val_accuracy: 0.9590\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.1077 - accuracy: 0.9685 - val_loss: 0.1139 - val_accuracy: 0.9637\n",
            "1/1 [==============================] - 0s 984us/step - loss: 0.0784 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.1012 - accuracy: 0.9711 - val_loss: 0.1151 - val_accuracy: 0.9613\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0982 - accuracy: 0.9730 - val_loss: 0.1108 - val_accuracy: 0.9645\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0893 - accuracy: 0.9751 - val_loss: 0.1107 - val_accuracy: 0.9645\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0727 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0870 - accuracy: 0.9746 - val_loss: 0.1064 - val_accuracy: 0.9660\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0815 - accuracy: 0.9765 - val_loss: 0.1037 - val_accuracy: 0.9664\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0787 - accuracy: 0.9780 - val_loss: 0.1012 - val_accuracy: 0.9680\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0683 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0743 - accuracy: 0.9793 - val_loss: 0.1006 - val_accuracy: 0.9672\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0697 - accuracy: 0.9802 - val_loss: 0.0967 - val_accuracy: 0.9688\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0665 - accuracy: 0.9815 - val_loss: 0.0943 - val_accuracy: 0.9695\n",
            "1/1 [==============================] - 0s 981us/step - loss: 0.0680 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0635 - accuracy: 0.9816 - val_loss: 0.0923 - val_accuracy: 0.9695\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0593 - accuracy: 0.9826 - val_loss: 0.0930 - val_accuracy: 0.9703\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0587 - accuracy: 0.9832 - val_loss: 0.0933 - val_accuracy: 0.9668\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0574 - accuracy: 0.9883\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0541 - accuracy: 0.9846 - val_loss: 0.0911 - val_accuracy: 0.9719\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0528 - accuracy: 0.9853 - val_loss: 0.0913 - val_accuracy: 0.9723\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0491 - accuracy: 0.9853 - val_loss: 0.0896 - val_accuracy: 0.9734\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0578 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0464 - accuracy: 0.9876 - val_loss: 0.0895 - val_accuracy: 0.9738\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0447 - accuracy: 0.9872 - val_loss: 0.0869 - val_accuracy: 0.9746\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0429 - accuracy: 0.9876 - val_loss: 0.0885 - val_accuracy: 0.9742\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0599 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0399 - accuracy: 0.9891 - val_loss: 0.0856 - val_accuracy: 0.9754\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0384 - accuracy: 0.9898 - val_loss: 0.0848 - val_accuracy: 0.9754\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0357 - accuracy: 0.9902 - val_loss: 0.0862 - val_accuracy: 0.9754\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 0.9883\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0351 - accuracy: 0.9897 - val_loss: 0.0844 - val_accuracy: 0.9750\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0330 - accuracy: 0.9914 - val_loss: 0.0851 - val_accuracy: 0.9746\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0318 - accuracy: 0.9911 - val_loss: 0.0835 - val_accuracy: 0.9754\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0523 - accuracy: 0.9883\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0310 - accuracy: 0.9920 - val_loss: 0.0843 - val_accuracy: 0.9754\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0283 - accuracy: 0.9926 - val_loss: 0.0820 - val_accuracy: 0.9766\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0275 - accuracy: 0.9930 - val_loss: 0.0815 - val_accuracy: 0.9773\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0523 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0261 - accuracy: 0.9928 - val_loss: 0.0839 - val_accuracy: 0.9777\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0252 - accuracy: 0.9934 - val_loss: 0.0797 - val_accuracy: 0.9785\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0222 - accuracy: 0.9949 - val_loss: 0.0836 - val_accuracy: 0.9770\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0521 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0211 - accuracy: 0.9947 - val_loss: 0.0838 - val_accuracy: 0.9773\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0221 - accuracy: 0.9942 - val_loss: 0.0841 - val_accuracy: 0.9758\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0213 - accuracy: 0.9945 - val_loss: 0.0824 - val_accuracy: 0.9770\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0496 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0199 - accuracy: 0.9953 - val_loss: 0.0835 - val_accuracy: 0.9777\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0179 - accuracy: 0.9962 - val_loss: 0.0834 - val_accuracy: 0.9785\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0184 - accuracy: 0.9954 - val_loss: 0.0824 - val_accuracy: 0.9797\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0501 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0172 - accuracy: 0.9960 - val_loss: 0.0804 - val_accuracy: 0.9789\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0176 - accuracy: 0.9956 - val_loss: 0.0836 - val_accuracy: 0.9773\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0149 - accuracy: 0.9967 - val_loss: 0.0818 - val_accuracy: 0.9789\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0547 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0154 - accuracy: 0.9964 - val_loss: 0.0832 - val_accuracy: 0.9762\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0150 - accuracy: 0.9964 - val_loss: 0.0860 - val_accuracy: 0.9758\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0143 - accuracy: 0.9961 - val_loss: 0.0831 - val_accuracy: 0.9770\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0563 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0141 - accuracy: 0.9966 - val_loss: 0.0843 - val_accuracy: 0.9773\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0132 - accuracy: 0.9969 - val_loss: 0.0858 - val_accuracy: 0.9781\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0136 - accuracy: 0.9966 - val_loss: 0.0838 - val_accuracy: 0.9766\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0516 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0136 - accuracy: 0.9965 - val_loss: 0.0811 - val_accuracy: 0.9789\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0118 - accuracy: 0.9976 - val_loss: 0.0846 - val_accuracy: 0.9770\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0112 - accuracy: 0.9977 - val_loss: 0.0860 - val_accuracy: 0.9762\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0498 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0116 - accuracy: 0.9973 - val_loss: 0.0835 - val_accuracy: 0.9785\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0099 - accuracy: 0.9979 - val_loss: 0.0820 - val_accuracy: 0.9770\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0096 - accuracy: 0.9981 - val_loss: 0.0854 - val_accuracy: 0.9777\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0496 - accuracy: 0.9883\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 0.0826 - val_accuracy: 0.9793\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0084 - accuracy: 0.9987 - val_loss: 0.0858 - val_accuracy: 0.9781\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0088 - accuracy: 0.9980 - val_loss: 0.0829 - val_accuracy: 0.9789\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0088 - accuracy: 0.9982 - val_loss: 0.0864 - val_accuracy: 0.9758\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.0844 - val_accuracy: 0.9785\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0077 - accuracy: 0.9986 - val_loss: 0.0843 - val_accuracy: 0.9773\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0465 - accuracy: 0.9883\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.0855 - val_accuracy: 0.9797\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.0856 - val_accuracy: 0.9781\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.0884 - val_accuracy: 0.9781\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0075 - accuracy: 0.9984 - val_loss: 0.0875 - val_accuracy: 0.9789\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.0854 - val_accuracy: 0.9781\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.0841 - val_accuracy: 0.9801\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0574 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.0868 - val_accuracy: 0.9789\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.0873 - val_accuracy: 0.9789\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.0856 - val_accuracy: 0.9793\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0656 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0057 - accuracy: 0.9990 - val_loss: 0.0872 - val_accuracy: 0.9797\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0051 - accuracy: 0.9992 - val_loss: 0.0835 - val_accuracy: 0.9805\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.0855 - val_accuracy: 0.9805\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0607 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.0882 - val_accuracy: 0.9793\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0855 - val_accuracy: 0.9785\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.0871 - val_accuracy: 0.9789\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0603 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.0859 - val_accuracy: 0.9805\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0044 - accuracy: 0.9993 - val_loss: 0.0845 - val_accuracy: 0.9801\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0043 - accuracy: 0.9993 - val_loss: 0.0884 - val_accuracy: 0.9793\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0604 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.0873 - val_accuracy: 0.9781\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0051 - accuracy: 0.9990 - val_loss: 0.0839 - val_accuracy: 0.9816\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0883 - val_accuracy: 0.9797\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0597 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.0864 - val_accuracy: 0.9793\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.0871 - val_accuracy: 0.9801\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.0884 - val_accuracy: 0.9781\n",
            "1/1 [==============================] - 0s 986us/step - loss: 0.0638 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.0933 - val_accuracy: 0.9777\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.0901 - val_accuracy: 0.9797\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.0902 - val_accuracy: 0.9777\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.0927 - val_accuracy: 0.9785\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.0871 - val_accuracy: 0.9793\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.0936 - val_accuracy: 0.9773\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0641 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.0963 - val_accuracy: 0.9781\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0025 - accuracy: 0.9997 - val_loss: 0.0950 - val_accuracy: 0.9777\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0974 - val_accuracy: 0.9773\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0705 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0927 - val_accuracy: 0.9793\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0917 - val_accuracy: 0.9785\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.0894 - val_accuracy: 0.9785\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0619 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 0.0937 - val_accuracy: 0.9785\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 0.0930 - val_accuracy: 0.9797\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.0936 - val_accuracy: 0.9793\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0613 - accuracy: 0.9883\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.0931 - val_accuracy: 0.9777\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0961 - val_accuracy: 0.9797\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.0924 - val_accuracy: 0.9801\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0661 - accuracy: 0.9883\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.0955 - val_accuracy: 0.9781\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.0963 - val_accuracy: 0.9781\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.0960 - val_accuracy: 0.9805\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0694 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0934 - val_accuracy: 0.9801\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0939 - val_accuracy: 0.9805\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0962 - val_accuracy: 0.9797\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0709 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0980 - val_accuracy: 0.9785\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0926 - val_accuracy: 0.9797\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0929 - val_accuracy: 0.9797\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0711 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.0914 - val_accuracy: 0.9797\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.0952 - val_accuracy: 0.9805\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0968 - val_accuracy: 0.9801\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0806 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0953 - val_accuracy: 0.9809\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0977 - val_accuracy: 0.9785\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0955 - val_accuracy: 0.9805\n",
            "1/1 [==============================] - 0s 943us/step - loss: 0.0695 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0994 - val_accuracy: 0.9781\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.0955 - val_accuracy: 0.9801\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0967 - val_accuracy: 0.9793\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0814 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.0945 - val_accuracy: 0.9820\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.1011 - val_accuracy: 0.9793\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0995 - val_accuracy: 0.9789\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0882 - accuracy: 0.9805\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.1008 - val_accuracy: 0.9805\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.1000 - val_accuracy: 0.9805\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.1028 - val_accuracy: 0.9805\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0850 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.1003 - val_accuracy: 0.9801\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0980 - val_accuracy: 0.9805\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0983 - val_accuracy: 0.9797\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0794 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.1039 - val_accuracy: 0.9793\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0997 - val_accuracy: 0.9781\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.1036 - val_accuracy: 0.9812\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0701 - accuracy: 0.9805\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.1039 - val_accuracy: 0.9793\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.1100 - val_accuracy: 0.9801\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.1018 - val_accuracy: 0.9797\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0834 - accuracy: 0.9805\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.1062 - val_accuracy: 0.9789\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.1003 - val_accuracy: 0.9801\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.1006 - val_accuracy: 0.9793\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0684 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.1041 - val_accuracy: 0.9789\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.1037 - val_accuracy: 0.9789\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.1052 - val_accuracy: 0.9793\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0802 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.1075 - val_accuracy: 0.9785\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.1058 - val_accuracy: 0.9801\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.1036 - val_accuracy: 0.9797\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0788 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.1049 - val_accuracy: 0.9801\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0961 - val_accuracy: 0.9809\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 9.2642e-04 - accuracy: 0.9998 - val_loss: 0.1008 - val_accuracy: 0.9793\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0761 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.1006 - val_accuracy: 0.9797\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.1042 - val_accuracy: 0.9793\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 9.0546e-04 - accuracy: 0.9999 - val_loss: 0.1091 - val_accuracy: 0.9789\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0802 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.1046 - val_accuracy: 0.9805\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1016 - val_accuracy: 0.9809\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.1015 - val_accuracy: 0.9824\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0775 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 7.4709e-04 - accuracy: 1.0000 - val_loss: 0.1032 - val_accuracy: 0.9816\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0986 - val_accuracy: 0.9828\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 9.9025e-04 - accuracy: 0.9998 - val_loss: 0.1027 - val_accuracy: 0.9820\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0742 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.1013 - val_accuracy: 0.9816\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 9.6624e-04 - accuracy: 0.9998 - val_loss: 0.1072 - val_accuracy: 0.9812\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.1067 - val_accuracy: 0.9805\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0853 - accuracy: 0.9844\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 8.9182e-04 - accuracy: 0.9999 - val_loss: 0.1130 - val_accuracy: 0.9781\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.1082 - val_accuracy: 0.9789\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.1097 - val_accuracy: 0.9805\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0743 - accuracy: 0.9883\n",
            "Epoch 1/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.1046 - val_accuracy: 0.9793\n",
            "Epoch 2/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 9.2099e-04 - accuracy: 0.9998 - val_loss: 0.1018 - val_accuracy: 0.9797\n",
            "Epoch 3/3\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.1087 - val_accuracy: 0.9793\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0906 - accuracy: 0.9844\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0906 - accuracy: 0.9844\n",
            "Test accuracy :  0.09056036919355392 0.984375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7ApRxERmfNa",
        "colab_type": "code",
        "outputId": "d3493769-d163-4b76-d0ef-2364327bbabe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(\"The time taken is \" + str(finish - start))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The time taken is 175.76650263500005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp2lCyyeJ08V",
        "colab_type": "text"
      },
      "source": [
        "Plotting the test error graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuXM7ZobXcId",
        "colab_type": "code",
        "outputId": "9d5cb4ee-ad46-437d-d727-9bd3fd68eb19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "# Plotting the graph of varying test error against weight updates\n",
        "plt.plot(x_plt, y_acc, color='green', linewidth = 1)\n",
        "plt.ylim(0,0.15) \n",
        "plt.xlim(0,18000) \n",
        "  \n",
        "# Naming the axes \n",
        "plt.xlabel('Number of weight updates')  \n",
        "plt.ylabel('Test error') \n",
        "  \n",
        "# Giving a title to the graph \n",
        "plt.title('Test Set') \n",
        "  \n",
        "# Displaying the plot \n",
        "plt.show()\n",
        "\n",
        "print(\"The time taken is \" + str(finish - start)) "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "The time taken is 175.76650263500005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f3Mw0Htyf_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}